{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras as keru\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import regularizers as rego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "riris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = riris.data\n",
    "y = riris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keru.utils.to_categorical(y_train)\n",
    "y_test = keru.utils.to_categorical(y_test)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 35ms/step - loss: 1.3688 - acc: 0.3596\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "89/89 [==============================] - 0s 95us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.2281 - acc: 0.3146\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      "89/89 [==============================] - 0s 85us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3412 - acc: 0.3333\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "90/90 [==============================] - 0s 86us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2039 - acc: 0.3000\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "90/90 [==============================] - 0s 116us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7248 - acc: 0.1778\n",
      "22/22 [==============================] - 0s 3ms/step\n",
      "90/90 [==============================] - 0s 110us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 2.6907 - acc: 0.2697\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "89/89 [==============================] - 0s 104us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 0s 5ms/step - loss: 1.5379 - acc: 0.3371\n",
      "23/23 [==============================] - 0s 4ms/step\n",
      "89/89 [==============================] - 0s 111us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.8815 - acc: 0.3333\n",
      "22/22 [==============================] - 0s 5ms/step\n",
      "90/90 [==============================] - 0s 107us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.3371 - acc: 0.3778\n",
      "22/22 [==============================] - 0s 6ms/step\n",
      "90/90 [==============================] - 0s 125us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.3544 - acc: 0.3222\n",
      "22/22 [==============================] - 0s 6ms/step\n",
      "90/90 [==============================] - 0s 113us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 0s 6ms/step - loss: 2.7995 - acc: 0.6067\n",
      "23/23 [==============================] - 0s 6ms/step\n",
      "89/89 [==============================] - 0s 110us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 6ms/step - loss: 3.8879 - acc: 0.3371\n",
      "23/23 [==============================] - 0s 8ms/step\n",
      "89/89 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.9098 - acc: 0.3444\n",
      "22/22 [==============================] - 0s 9ms/step\n",
      "90/90 [==============================] - 0s 126us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.1268 - acc: 0.3222\n",
      "22/22 [==============================] - 0s 9ms/step\n",
      "90/90 [==============================] - 0s 125us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 2.9563 - acc: 0.4556\n",
      "22/22 [==============================] - 0s 9ms/step\n",
      "90/90 [==============================] - 0s 119us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 7ms/step - loss: 18.7015 - acc: 0.2697\n",
      "23/23 [==============================] - 0s 9ms/step\n",
      "89/89 [==============================] - 0s 138us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 8ms/step - loss: 18.4889 - acc: 0.3371\n",
      "23/23 [==============================] - 0s 10ms/step\n",
      "89/89 [==============================] - 0s 121us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 18.1165 - acc: 0.3333\n",
      "22/22 [==============================] - 0s 10ms/step\n",
      "90/90 [==============================] - 0s 115us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 21.1761 - acc: 0.3000\n",
      "22/22 [==============================] - 0s 12ms/step\n",
      "90/90 [==============================] - 0s 115us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 19.3769 - acc: 0.3111\n",
      "22/22 [==============================] - 0s 12ms/step\n",
      "90/90 [==============================] - 0s 111us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 9ms/step - loss: 196.2419 - acc: 0.2697\n",
      "23/23 [==============================] - 0s 12ms/step\n",
      "89/89 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 10ms/step - loss: 168.7856 - acc: 0.3371\n",
      "23/23 [==============================] - 0s 13ms/step\n",
      "89/89 [==============================] - 0s 128us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 173.4465 - acc: 0.6556\n",
      "22/22 [==============================] - 0s 14ms/step\n",
      "90/90 [==============================] - 0s 116us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 204.2441 - acc: 0.3000\n",
      "22/22 [==============================] - 0s 15ms/step\n",
      "90/90 [==============================] - 0s 114us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 184.0006 - acc: 0.3444\n",
      "22/22 [==============================] - 0s 16ms/step\n",
      "90/90 [==============================] - 0s 109us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 1835.6122 - acc: 0.4045\n",
      "23/23 [==============================] - 0s 17ms/step\n",
      "89/89 [==============================] - 0s 113us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 1584.1593 - acc: 0.3371\n",
      "23/23 [==============================] - 0s 16ms/step\n",
      "89/89 [==============================] - 0s 117us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 1718.6831 - acc: 0.3222\n",
      "22/22 [==============================] - 0s 18ms/step\n",
      "90/90 [==============================] - 0s 110us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 1726.7023 - acc: 0.3000\n",
      "22/22 [==============================] - 0s 19ms/step\n",
      "90/90 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 13ms/step - loss: 1691.1089 - acc: 0.3222\n",
      "22/22 [==============================] - 0s 19ms/step\n",
      "90/90 [==============================] - 0s 124us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.9505 - acc: 0.6404\n",
      "23/23 [==============================] - 0s 20ms/step\n",
      "89/89 [==============================] - 0s 112us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 1.6296 - acc: 0.3371\n",
      "23/23 [==============================] - 0s 20ms/step\n",
      "89/89 [==============================] - 0s 116us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 3.4088 - acc: 0.3444\n",
      "22/22 [==============================] - 0s 22ms/step\n",
      "90/90 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 1.3751 - acc: 0.3778\n",
      "22/22 [==============================] - 0s 22ms/step\n",
      "90/90 [==============================] - 0s 134us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 1.1577 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 23ms/step\n",
      "90/90 [==============================] - 0s 135us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 1.3439 - acc: 0.3708\n",
      "23/23 [==============================] - 1s 23ms/step\n",
      "89/89 [==============================] - 0s 141us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 2.3266 - acc: 0.3258\n",
      "23/23 [==============================] - 1s 23ms/step\n",
      "89/89 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 1.8274 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 25ms/step\n",
      "90/90 [==============================] - 0s 123us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 1.7849 - acc: 0.3778\n",
      "22/22 [==============================] - 1s 27ms/step\n",
      "90/90 [==============================] - 0s 124us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 1s 17ms/step - loss: 1.5210 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 26ms/step\n",
      "90/90 [==============================] - 0s 121us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 17ms/step - loss: 3.8364 - acc: 0.6404\n",
      "23/23 [==============================] - 1s 27ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 124us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 17ms/step - loss: 3.3992 - acc: 0.3596\n",
      "23/23 [==============================] - 1s 26ms/step\n",
      "89/89 [==============================] - 0s 115us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 4.7458 - acc: 0.3333\n",
      "22/22 [==============================] - 1s 29ms/step\n",
      "90/90 [==============================] - 0s 117us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 3.9855 - acc: 0.3000\n",
      "22/22 [==============================] - 1s 32ms/step\n",
      "90/90 [==============================] - 0s 134us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 4.0388 - acc: 0.3444\n",
      "22/22 [==============================] - 1s 32ms/step\n",
      "90/90 [==============================] - 0s 118us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 19ms/step - loss: 26.0756 - acc: 0.3596\n",
      "23/23 [==============================] - 1s 32ms/step\n",
      "89/89 [==============================] - 0s 140us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 20ms/step - loss: 24.2246 - acc: 0.3371\n",
      "23/23 [==============================] - 1s 31ms/step\n",
      "89/89 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 25.5461 - acc: 0.6556\n",
      "22/22 [==============================] - 1s 35ms/step\n",
      "90/90 [==============================] - 0s 120us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 24.8220 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 34ms/step\n",
      "90/90 [==============================] - 0s 135us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 21ms/step - loss: 24.6353 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 35ms/step\n",
      "90/90 [==============================] - 0s 121us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 22ms/step - loss: 240.5399 - acc: 0.3596\n",
      "23/23 [==============================] - 1s 34ms/step\n",
      "89/89 [==============================] - 0s 124us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 22ms/step - loss: 248.8470 - acc: 0.3483\n",
      "23/23 [==============================] - 1s 35ms/step\n",
      "89/89 [==============================] - 0s 133us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 22ms/step - loss: 223.3214 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 38ms/step\n",
      "90/90 [==============================] - 0s 126us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 23ms/step - loss: 244.1022 - acc: 0.3000\n",
      "22/22 [==============================] - 1s 38ms/step\n",
      "90/90 [==============================] - 0s 143us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 24ms/step - loss: 219.3900 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 40ms/step\n",
      "90/90 [==============================] - 0s 122us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 24ms/step - loss: 2218.5693 - acc: 0.6180\n",
      "23/23 [==============================] - 1s 38ms/step\n",
      "89/89 [==============================] - 0s 127us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 24ms/step - loss: 2480.4718 - acc: 0.5618\n",
      "23/23 [==============================] - 1s 39ms/step\n",
      "89/89 [==============================] - 0s 130us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 25ms/step - loss: 2348.4757 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 42ms/step\n",
      "90/90 [==============================] - 0s 148us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 25ms/step - loss: 2206.7627 - acc: 0.6778\n",
      "22/22 [==============================] - 1s 43ms/step\n",
      "90/90 [==============================] - 0s 135us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 25ms/step - loss: 2251.2361 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 43ms/step\n",
      "90/90 [==============================] - 0s 136us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 26ms/step - loss: 1.4412 - acc: 0.3708\n",
      "23/23 [==============================] - 1s 42ms/step\n",
      "89/89 [==============================] - 0s 140us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 2s 27ms/step - loss: 0.9931 - acc: 0.3933\n",
      "23/23 [==============================] - 1s 44ms/step\n",
      "89/89 [==============================] - 0s 126us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 1.7856 - acc: 0.3444\n",
      "22/22 [==============================] - 1s 46ms/step\n",
      "90/90 [==============================] - 0s 140us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 1.4589 - acc: 0.3000\n",
      "22/22 [==============================] - 1s 47ms/step\n",
      "90/90 [==============================] - 0s 122us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 1.2831 - acc: 0.3444\n",
      "22/22 [==============================] - 1s 48ms/step\n",
      "90/90 [==============================] - 0s 120us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 2.7387 - acc: 0.2697\n",
      "23/23 [==============================] - 1s 47ms/step\n",
      "89/89 [==============================] - 0s 138us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 29ms/step - loss: 1.3365 - acc: 0.4270\n",
      "23/23 [==============================] - 1s 47ms/step\n",
      "89/89 [==============================] - 0s 137us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 2.3432 - acc: 0.3333\n",
      "22/22 [==============================] - 1s 51ms/step\n",
      "90/90 [==============================] - 0s 135us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 1.5570 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 52ms/step\n",
      "90/90 [==============================] - 0s 128us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 2.3947 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 52ms/step\n",
      "90/90 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 30ms/step - loss: 6.3924 - acc: 0.2697\n",
      "23/23 [==============================] - 1s 51ms/step\n",
      "89/89 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 31ms/step - loss: 6.1239 - acc: 0.3258\n",
      "23/23 [==============================] - 1s 51ms/step\n",
      "89/89 [==============================] - 0s 143us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 5.1654 - acc: 0.3444\n",
      "22/22 [==============================] - 1s 53ms/step\n",
      "90/90 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 5.2141 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 56ms/step\n",
      "90/90 [==============================] - 0s 137us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 5.3587 - acc: 0.3333\n",
      "22/22 [==============================] - 1s 57ms/step\n",
      "90/90 [==============================] - 0s 140us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 33ms/step - loss: 37.8044 - acc: 0.4382\n",
      "23/23 [==============================] - 1s 54ms/step\n",
      "89/89 [==============================] - 0s 132us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 33ms/step - loss: 40.9835 - acc: 0.5281\n",
      "23/23 [==============================] - 1s 55ms/step\n",
      "89/89 [==============================] - 0s 137us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 33ms/step - loss: 39.2756 - acc: 0.3556\n",
      "22/22 [==============================] - 1s 60ms/step\n",
      "90/90 [==============================] - 0s 150us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 34ms/step - loss: 38.8603 - acc: 0.3778\n",
      "22/22 [==============================] - 1s 61ms/step\n",
      "90/90 [==============================] - 0s 134us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 34ms/step - loss: 40.0682 - acc: 0.3444\n",
      "22/22 [==============================] - 1s 60ms/step\n",
      "90/90 [==============================] - 0s 150us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 35ms/step - loss: 391.8169 - acc: 0.3596\n",
      "23/23 [==============================] - 1s 59ms/step\n",
      "89/89 [==============================] - 0s 146us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 36ms/step - loss: 409.3971 - acc: 0.4045\n",
      "23/23 [==============================] - 1s 60ms/step\n",
      "89/89 [==============================] - 0s 132us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 36ms/step - loss: 400.0166 - acc: 0.3333\n",
      "22/22 [==============================] - 1s 63ms/step\n",
      "90/90 [==============================] - 0s 140us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 395.4131 - acc: 0.3778\n",
      "22/22 [==============================] - 1s 65ms/step\n",
      "90/90 [==============================] - 0s 160us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 397.5394 - acc: 0.0000e+00\n",
      "22/22 [==============================] - 1s 66ms/step\n",
      "90/90 [==============================] - 0s 148us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 38ms/step - loss: 3983.0386 - acc: 0.0000e+00\n",
      "23/23 [==============================] - 1s 63ms/step\n",
      "89/89 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 3s 38ms/step - loss: 3948.7716 - acc: 0.3371\n",
      "23/23 [==============================] - 1s 64ms/step\n",
      "89/89 [==============================] - 0s 133us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 4047.9162 - acc: 0.3222\n",
      "22/22 [==============================] - 1s 66ms/step\n",
      "90/90 [==============================] - 0s 149us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 3934.6391 - acc: 0.3778\n",
      "22/22 [==============================] - 1s 68ms/step\n",
      "90/90 [==============================] - 0s 145us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 39ms/step - loss: 3787.3885 - acc: 0.3444\n",
      "22/22 [==============================] - 2s 70ms/step\n",
      "90/90 [==============================] - 0s 144us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 4s 40ms/step - loss: 1.6255 - acc: 0.2697\n",
      "23/23 [==============================] - 2s 68ms/step\n",
      "89/89 [==============================] - 0s 144us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 4s 41ms/step - loss: 1.5513 - acc: 0.3258\n",
      "23/23 [==============================] - 2s 68ms/step\n",
      "89/89 [==============================] - 0s 160us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 1.3858 - acc: 0.0778\n",
      "22/22 [==============================] - 2s 73ms/step\n",
      "90/90 [==============================] - 0s 146us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 1.1442 - acc: 0.3333\n",
      "22/22 [==============================] - 2s 72ms/step\n",
      "90/90 [==============================] - 0s 136us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 41ms/step - loss: 1.7433 - acc: 0.3333\n",
      "22/22 [==============================] - 2s 74ms/step\n",
      "90/90 [==============================] - 0s 152us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 4s 42ms/step - loss: 1.6320 - acc: 0.3596\n",
      "23/23 [==============================] - 2s 72ms/step\n",
      "89/89 [==============================] - 0s 175us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 4s 43ms/step - loss: 2.0562 - acc: 0.3371\n",
      "23/23 [==============================] - 2s 75ms/step\n",
      "89/89 [==============================] - 0s 158us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 1.4783 - acc: 0.6556\n",
      "22/22 [==============================] - 2s 77ms/step\n",
      "90/90 [==============================] - 0s 159us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 43ms/step - loss: 1.5886 - acc: 0.3000\n",
      "22/22 [==============================] - 2s 78ms/step\n",
      "90/90 [==============================] - 0s 151us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 44ms/step - loss: 2.1962 - acc: 0.3333\n",
      "22/22 [==============================] - 2s 78ms/step\n",
      "90/90 [==============================] - 0s 151us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 6.1672 - acc: 0.3596\n",
      "23/23 [==============================] - 2s 75ms/step\n",
      "89/89 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 4s 45ms/step - loss: 6.4413 - acc: 0.1461\n",
      "23/23 [==============================] - 2s 75ms/step\n",
      "89/89 [==============================] - 0s 155us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 6.2727 - acc: 0.6667\n",
      "22/22 [==============================] - 2s 80ms/step\n",
      "90/90 [==============================] - 0s 151us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 45ms/step - loss: 6.4622 - acc: 0.2111\n",
      "22/22 [==============================] - 2s 82ms/step\n",
      "90/90 [==============================] - 0s 142us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 46ms/step - loss: 7.1770 - acc: 0.3444\n",
      "22/22 [==============================] - 2s 82ms/step\n",
      "90/90 [==============================] - 0s 160us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 4s 47ms/step - loss: 50.6409 - acc: 0.2697\n",
      "23/23 [==============================] - 2s 80ms/step\n",
      "89/89 [==============================] - 0s 139us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 4s 48ms/step - loss: 51.4403 - acc: 0.3258\n",
      "23/23 [==============================] - 2s 82ms/step\n",
      "89/89 [==============================] - 0s 150us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 50.2331 - acc: 0.3333\n",
      "22/22 [==============================] - 2s 86ms/step\n",
      "90/90 [==============================] - 0s 129us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 49ms/step - loss: 49.8842 - acc: 0.3556\n",
      "22/22 [==============================] - 2s 88ms/step\n",
      "90/90 [==============================] - 0s 154us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 4s 48ms/step - loss: 50.6043 - acc: 0.3444\n",
      "22/22 [==============================] - 2s 88ms/step\n",
      "90/90 [==============================] - 0s 154us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 4s 50ms/step - loss: 486.5745 - acc: 0.2697\n",
      "23/23 [==============================] - 2s 85ms/step\n",
      "89/89 [==============================] - 0s 153us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 5s 51ms/step - loss: 497.8315 - acc: 0.3258\n",
      "23/23 [==============================] - 2s 85ms/step\n",
      "89/89 [==============================] - 0s 158us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 5s 50ms/step - loss: 512.8432 - acc: 0.3222\n",
      "22/22 [==============================] - 2s 92ms/step\n",
      "90/90 [==============================] - 0s 160us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 496.0457 - acc: 0.3222\n",
      "22/22 [==============================] - 2s 92ms/step\n",
      "90/90 [==============================] - 0s 164us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 5s 51ms/step - loss: 507.6345 - acc: 0.6778\n",
      "22/22 [==============================] - 2s 93ms/step\n",
      "90/90 [==============================] - 0s 159us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 5s 52ms/step - loss: 4974.4372 - acc: 0.0000e+00\n",
      "23/23 [==============================] - 2s 91ms/step\n",
      "89/89 [==============================] - 0s 149us/step\n",
      "Epoch 1/1\n",
      "89/89 [==============================] - 5s 53ms/step - loss: 4993.5971 - acc: 0.3371\n",
      "23/23 [==============================] - 2s 89ms/step\n",
      "89/89 [==============================] - 0s 140us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 5s 52ms/step - loss: 4833.3095 - acc: 0.6667\n",
      "22/22 [==============================] - 2s 96ms/step\n",
      "90/90 [==============================] - 0s 159us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 4865.2795 - acc: 0.3778\n",
      "22/22 [==============================] - 2s 97ms/step\n",
      "90/90 [==============================] - 0s 175us/step\n",
      "Epoch 1/1\n",
      "90/90 [==============================] - 5s 53ms/step - loss: 4871.8581 - acc: 0.3222\n",
      "22/22 [==============================] - 2s 98ms/step\n",
      "90/90 [==============================] - 0s 152us/step\n",
      "Epoch 1/1\n",
      "112/112 [==============================] - 5s 43ms/step - loss: 2471.1558 - acc: 0.3393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f764f8b47b8>,\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'hidden_size1': [8, 12, 32, 64], 'reg': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the slides\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def make_model(optimizer=\"adam\", hidden_size1=32, hidden_size2=32, reg = 0.01):\n",
    "    model = Sequential([\n",
    "    Dense(hidden_size1, input_shape=(4,), kernel_regularizer=rego.l2(reg)),\n",
    "    Activation('relu'),\n",
    "    Dense(hidden_size2, kernel_regularizer=rego.l2(reg)),\n",
    "    Activation('relu'),\n",
    "    Dense(3),\n",
    "    Activation('softmax'),\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",   \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "clf = KerasClassifier(make_model)\n",
    "param_grid = {'hidden_size1': [8,12,32,64],'hidden_size2': [8,12,32,64], 'reg' :[0.001,0.01,0.1,1,10,100] # epochs is fit parameter, not in make_model!\n",
    "              }\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 2s 57ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31578947446848216"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ecbm4040/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ecbm4040/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ecbm4040/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ecbm4040/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ecbm4040/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ecbm4040/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_reg</th>\n",
       "      <th>param_hidden_size1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.001</th>\n",
       "      <th>8</th>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.283745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.404395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.366071</td>\n",
       "      <td>0.386542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.281323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.010</th>\n",
       "      <th>8</th>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.328015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.343770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.401786</td>\n",
       "      <td>0.330387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.410437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.100</th>\n",
       "      <th>8</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.413233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.455357</td>\n",
       "      <td>0.404544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.316879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.278602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1.000</th>\n",
       "      <th>8</th>\n",
       "      <td>0.383929</td>\n",
       "      <td>0.303571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.399326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.366071</td>\n",
       "      <td>0.408739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.336879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10.000</th>\n",
       "      <th>8</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.381348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.366071</td>\n",
       "      <td>0.332709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.297278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.455357</td>\n",
       "      <td>0.379101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">100.000</th>\n",
       "      <th>8</th>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.355181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.508929</td>\n",
       "      <td>0.491411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.241071</td>\n",
       "      <td>0.278552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.340749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              mean_test_score  mean_train_score\n",
       "param_reg param_hidden_size1                                   \n",
       "0.001     8                          0.303571          0.283745\n",
       "          12                         0.383929          0.404395\n",
       "          32                         0.366071          0.386542\n",
       "          64                         0.348214          0.281323\n",
       "0.010     8                          0.339286          0.328015\n",
       "          12                         0.294643          0.343770\n",
       "          32                         0.401786          0.330387\n",
       "          64                         0.410714          0.410437\n",
       "0.100     8                          0.437500          0.413233\n",
       "          12                         0.455357          0.404544\n",
       "          32                         0.383929          0.316879\n",
       "          64                         0.232143          0.278602\n",
       "1.000     8                          0.383929          0.303571\n",
       "          12                         0.410714          0.399326\n",
       "          32                         0.366071          0.408739\n",
       "          64                         0.437500          0.336879\n",
       "10.000    8                          0.437500          0.381348\n",
       "          12                         0.366071          0.332709\n",
       "          32                         0.196429          0.297278\n",
       "          64                         0.455357          0.379101\n",
       "100.000   8                          0.410714          0.355181\n",
       "          12                         0.508929          0.491411\n",
       "          32                         0.241071          0.278552\n",
       "          64                         0.276786          0.340749"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(grid.cv_results_)\n",
    "res.pivot_table(index=[\"param_reg\", \"param_hidden_size1\"],\n",
    "                values=['mean_train_score', \"mean_test_score\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "X_train_images = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test_images = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "y_train = keru.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keru.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "num_classes = 10\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 5s 93us/step - loss: 0.9779 - acc: 0.8847 - val_loss: 0.0927 - val_acc: 0.9760\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 4s 76us/step - loss: 0.0786 - acc: 0.9760 - val_loss: 0.0753 - val_acc: 0.9792\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 4s 76us/step - loss: 0.0531 - acc: 0.9839 - val_loss: 0.0554 - val_acc: 0.9855\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 4s 77us/step - loss: 0.0369 - acc: 0.9885 - val_loss: 0.0594 - val_acc: 0.9838\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0310 - acc: 0.9901 - val_loss: 0.0561 - val_acc: 0.9845\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0270 - acc: 0.9911 - val_loss: 0.0566 - val_acc: 0.9860\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 4s 76us/step - loss: 0.0234 - acc: 0.9923 - val_loss: 0.0552 - val_acc: 0.9870\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0217 - acc: 0.9927 - val_loss: 0.0475 - val_acc: 0.9877\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 4s 76us/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.0601 - val_acc: 0.9858\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0158 - acc: 0.9947 - val_loss: 0.0664 - val_acc: 0.9863\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 4s 76us/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0558 - val_acc: 0.9865\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 4s 76us/step - loss: 0.0164 - acc: 0.9950 - val_loss: 0.0725 - val_acc: 0.9862\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0154 - acc: 0.9952 - val_loss: 0.0568 - val_acc: 0.9902\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0193 - acc: 0.9943 - val_loss: 0.0638 - val_acc: 0.9867\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0685 - val_acc: 0.9872\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0634 - val_acc: 0.9888\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0643 - val_acc: 0.9892\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0601 - val_acc: 0.9887\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 4s 76us/step - loss: 0.0095 - acc: 0.9969 - val_loss: 0.0633 - val_acc: 0.9900\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0112 - acc: 0.9966 - val_loss: 0.0619 - val_acc: 0.9890\n",
      "10000/10000 [==============================] - 1s 74us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07738667782023835, 0.9852]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history_cnn = cnn.fit(X_train_images, y_train,\n",
    "                      batch_size=128, epochs=20, verbose=1, validation_split=.1)\n",
    "cnn.evaluate(X_test_images, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 4s 81us/step - loss: 4.9478 - acc: 0.6614 - val_loss: 0.3594 - val_acc: 0.9152\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.2650 - acc: 0.9293 - val_loss: 0.0926 - val_acc: 0.9698\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.1375 - acc: 0.9592 - val_loss: 0.0689 - val_acc: 0.9787\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.1042 - acc: 0.9686 - val_loss: 0.0579 - val_acc: 0.9828\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0878 - acc: 0.9735 - val_loss: 0.0520 - val_acc: 0.9863\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0744 - acc: 0.9773 - val_loss: 0.0558 - val_acc: 0.9832\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 4s 73us/step - loss: 0.0647 - acc: 0.9803 - val_loss: 0.0418 - val_acc: 0.9893\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0591 - acc: 0.9818 - val_loss: 0.0417 - val_acc: 0.9895\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0529 - acc: 0.9835 - val_loss: 0.0368 - val_acc: 0.9902\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0495 - acc: 0.9844 - val_loss: 0.0423 - val_acc: 0.9900\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0466 - acc: 0.9857 - val_loss: 0.0403 - val_acc: 0.9885\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0437 - acc: 0.9859 - val_loss: 0.0383 - val_acc: 0.9895\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0422 - acc: 0.9866 - val_loss: 0.0494 - val_acc: 0.9888\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0371 - acc: 0.9879 - val_loss: 0.0421 - val_acc: 0.9897\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 4s 75us/step - loss: 0.0368 - acc: 0.9883 - val_loss: 0.0455 - val_acc: 0.9878\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0347 - acc: 0.9891 - val_loss: 0.0444 - val_acc: 0.9878\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0313 - acc: 0.9900 - val_loss: 0.0442 - val_acc: 0.9897\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0302 - acc: 0.9898 - val_loss: 0.0459 - val_acc: 0.9893\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 4s 74us/step - loss: 0.0308 - acc: 0.9898 - val_loss: 0.0426 - val_acc: 0.9900\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 4s 76us/step - loss: 0.0278 - acc: 0.9913 - val_loss: 0.0403 - val_acc: 0.9897\n",
      "10000/10000 [==============================] - 1s 76us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.036118852441035236, 0.9893]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_drop = Sequential()\n",
    "cnn_drop.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "cnn_drop.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_drop.add(Dropout(0.5))\n",
    "cnn_drop.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn_drop.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_drop.add(Flatten())\n",
    "cnn_drop.add(Dense(64, activation='relu'))\n",
    "cnn_drop.add(Dense(num_classes, activation='softmax'))\n",
    "cnn_drop.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history_cnn = cnn_drop.fit(X_train_images, y_train,\n",
    "                      batch_size=128, epochs=20, verbose=1, validation_split=.1)\n",
    "cnn_drop.evaluate(X_test_images, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = sio.loadmat(\"train_32x32.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = sio.loadmat(\"test_32x32.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X', '__version__', '__globals__', 'y', '__header__'])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train[\"X\"]\n",
    "X_test = test[\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train[\"y\"]\n",
    "y_test = test[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3, 73257)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(73257,)\n",
    "y_test = y_test.reshape(26032,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# the data, shuffled and split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "X_train  =  np.transpose(train[\"X\"], (3, 0,1, 2))\n",
    "X_test  =  np.transpose(test[\"X\"], (3, 0,1, 2))\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "#y_train = keru.utils.to_categorical(y_train)\n",
    "#y_test = keru.utils.to_categorical(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73257, 32, 32, 3)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65931 samples, validate on 7326 samples\n",
      "Epoch 1/30\n",
      "65931/65931 [==============================] - 5s 81us/step - loss: 1.8663 - acc: 0.4376 - val_loss: 1.0944 - val_acc: 0.6560\n",
      "Epoch 2/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.8739 - acc: 0.7425 - val_loss: 0.7394 - val_acc: 0.7841\n",
      "Epoch 3/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.6869 - acc: 0.7998 - val_loss: 0.6552 - val_acc: 0.8163\n",
      "Epoch 4/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.5960 - acc: 0.8237 - val_loss: 0.5865 - val_acc: 0.8311\n",
      "Epoch 5/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.5313 - acc: 0.8441 - val_loss: 0.6438 - val_acc: 0.8034\n",
      "Epoch 6/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.4993 - acc: 0.8514 - val_loss: 0.6146 - val_acc: 0.8246\n",
      "Epoch 7/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.4647 - acc: 0.8619 - val_loss: 0.5662 - val_acc: 0.8430\n",
      "Epoch 8/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.4393 - acc: 0.8695 - val_loss: 0.5573 - val_acc: 0.8414\n",
      "Epoch 9/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.4153 - acc: 0.8759 - val_loss: 0.5208 - val_acc: 0.8571\n",
      "Epoch 10/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.3983 - acc: 0.8800 - val_loss: 0.5847 - val_acc: 0.8374\n",
      "Epoch 11/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.3796 - acc: 0.8848 - val_loss: 0.5371 - val_acc: 0.8444\n",
      "Epoch 12/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.3599 - acc: 0.8908 - val_loss: 0.5122 - val_acc: 0.8645\n",
      "Epoch 13/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.3410 - acc: 0.8969 - val_loss: 0.5686 - val_acc: 0.8470\n",
      "Epoch 14/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.3320 - acc: 0.8999 - val_loss: 0.5236 - val_acc: 0.8556\n",
      "Epoch 15/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.3155 - acc: 0.9057 - val_loss: 0.5406 - val_acc: 0.8635\n",
      "Epoch 16/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.3021 - acc: 0.9076 - val_loss: 0.5503 - val_acc: 0.8575\n",
      "Epoch 17/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.3041 - acc: 0.9065 - val_loss: 0.5319 - val_acc: 0.8651\n",
      "Epoch 18/30\n",
      "65931/65931 [==============================] - 5s 73us/step - loss: 0.2863 - acc: 0.9126 - val_loss: 0.5397 - val_acc: 0.8600\n",
      "Epoch 19/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.2706 - acc: 0.9174 - val_loss: 0.5581 - val_acc: 0.8604\n",
      "Epoch 20/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.2734 - acc: 0.9166 - val_loss: 0.5642 - val_acc: 0.8590\n",
      "Epoch 21/30\n",
      "65931/65931 [==============================] - 5s 73us/step - loss: 0.2574 - acc: 0.9209 - val_loss: 0.5622 - val_acc: 0.8627\n",
      "Epoch 22/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.2509 - acc: 0.9226 - val_loss: 0.5884 - val_acc: 0.8628\n",
      "Epoch 23/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.2415 - acc: 0.9266 - val_loss: 0.6371 - val_acc: 0.8474\n",
      "Epoch 24/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.2402 - acc: 0.9255 - val_loss: 0.5982 - val_acc: 0.8647\n",
      "Epoch 25/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.2318 - acc: 0.9291 - val_loss: 0.5952 - val_acc: 0.8680\n",
      "Epoch 26/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.2266 - acc: 0.9302 - val_loss: 0.6182 - val_acc: 0.8643\n",
      "Epoch 27/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.2204 - acc: 0.9322 - val_loss: 0.6337 - val_acc: 0.8606\n",
      "Epoch 28/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.2157 - acc: 0.9332 - val_loss: 0.6343 - val_acc: 0.8650\n",
      "Epoch 29/30\n",
      "65931/65931 [==============================] - 5s 74us/step - loss: 0.2068 - acc: 0.9366 - val_loss: 0.6532 - val_acc: 0.8621\n",
      "Epoch 30/30\n",
      "65931/65931 [==============================] - 5s 75us/step - loss: 0.2061 - acc: 0.9358 - val_loss: 0.6581 - val_acc: 0.8600\n",
      "26032/26032 [==============================] - 2s 80us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7752083152299032, 0.8533343577135832]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "num_class = 10\n",
    "cnn_small_bn = Sequential()\n",
    "cnn_small_bn.add(Conv2D(8, kernel_size=(3, 3), padding=\"valid\",\n",
    "                 input_shape=input_shape))\n",
    "cnn_small_bn.add(Activation(\"relu\"))\n",
    "#cnn_small_bn.add(BatchNormalization())\n",
    "cnn_small_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_small_bn.add(Conv2D(16, (3, 3), padding=\"valid\"))\n",
    "cnn_small_bn.add(Activation(\"relu\"))\n",
    "#cnn_small_bn.add(BatchNormalization())\n",
    "cnn_small_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_small_bn.add(Flatten())\n",
    "cnn_small_bn.add(Dense(64, activation='relu'))\n",
    "cnn_small_bn.add(Dense(num_classes, activation='softmax'))\n",
    "cnn_small_bn.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history_cnn_bn = cnn_small_bn.fit(X_train, y_train, batch_size=128, epochs=30, verbose=1, validation_split=.1)\n",
    "cnn_small_bn.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X_train[69,:,:,:], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6baaa3db70>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[43,:,:,:], interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65931 samples, validate on 7326 samples\n",
      "Epoch 1/20\n",
      "65931/65931 [==============================] - 12s 182us/step - loss: 1.1094 - acc: 0.7648 - val_loss: 0.8264 - val_acc: 0.8170\n",
      "Epoch 2/20\n",
      "65931/65931 [==============================] - 10s 153us/step - loss: 0.5850 - acc: 0.8805 - val_loss: 0.7657 - val_acc: 0.8303\n",
      "Epoch 3/20\n",
      "65931/65931 [==============================] - 10s 147us/step - loss: 0.4942 - acc: 0.8964 - val_loss: 0.6045 - val_acc: 0.8661\n",
      "Epoch 4/20\n",
      "65931/65931 [==============================] - 10s 147us/step - loss: 0.4370 - acc: 0.9082 - val_loss: 0.4651 - val_acc: 0.9019\n",
      "Epoch 5/20\n",
      "65931/65931 [==============================] - 10s 148us/step - loss: 0.4101 - acc: 0.9155 - val_loss: 0.4746 - val_acc: 0.8934\n",
      "Epoch 6/20\n",
      "65931/65931 [==============================] - 10s 146us/step - loss: 0.3873 - acc: 0.9213 - val_loss: 0.4355 - val_acc: 0.9115\n",
      "Epoch 7/20\n",
      "65931/65931 [==============================] - 10s 146us/step - loss: 0.3764 - acc: 0.9240 - val_loss: 0.4468 - val_acc: 0.9038\n",
      "Epoch 8/20\n",
      "65931/65931 [==============================] - 10s 145us/step - loss: 0.3585 - acc: 0.9280 - val_loss: 0.4628 - val_acc: 0.9019\n",
      "Epoch 9/20\n",
      "65931/65931 [==============================] - 10s 146us/step - loss: 0.3440 - acc: 0.9339 - val_loss: 0.4479 - val_acc: 0.9068\n",
      "Epoch 10/20\n",
      "65931/65931 [==============================] - 10s 146us/step - loss: 0.3299 - acc: 0.9355 - val_loss: 0.5160 - val_acc: 0.8782\n",
      "Epoch 11/20\n",
      "65931/65931 [==============================] - 10s 145us/step - loss: 0.3155 - acc: 0.9399 - val_loss: 0.5210 - val_acc: 0.8795\n",
      "Epoch 12/20\n",
      "65931/65931 [==============================] - 10s 145us/step - loss: 0.3001 - acc: 0.9444 - val_loss: 0.6710 - val_acc: 0.8301\n",
      "Epoch 13/20\n",
      "65931/65931 [==============================] - 10s 146us/step - loss: 0.2963 - acc: 0.9449 - val_loss: 0.4304 - val_acc: 0.9106\n",
      "Epoch 14/20\n",
      "65931/65931 [==============================] - 10s 145us/step - loss: 0.2756 - acc: 0.9503 - val_loss: 0.4986 - val_acc: 0.8979\n",
      "Epoch 15/20\n",
      "65931/65931 [==============================] - 10s 145us/step - loss: 0.2694 - acc: 0.9515 - val_loss: 0.4669 - val_acc: 0.9021\n",
      "Epoch 16/20\n",
      "65931/65931 [==============================] - 10s 145us/step - loss: 0.2601 - acc: 0.9541 - val_loss: 3.6954 - val_acc: 0.4130\n",
      "Epoch 17/20\n",
      "65931/65931 [==============================] - 9s 144us/step - loss: 0.2748 - acc: 0.9525 - val_loss: 0.5325 - val_acc: 0.8832\n",
      "Epoch 18/20\n",
      "65931/65931 [==============================] - 10s 145us/step - loss: 0.2460 - acc: 0.9581 - val_loss: 0.4948 - val_acc: 0.9014\n",
      "Epoch 19/20\n",
      "65931/65931 [==============================] - 10s 145us/step - loss: 0.2458 - acc: 0.9590 - val_loss: 0.5351 - val_acc: 0.8904\n",
      "Epoch 20/20\n",
      "65931/65931 [==============================] - 10s 144us/step - loss: 0.2316 - acc: 0.9627 - val_loss: 0.5087 - val_acc: 0.8978\n",
      "26032/26032 [==============================] - 3s 129us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5498426361965415, 0.894860172095882]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "regularizer = l2()\n",
    "\n",
    "num_class = 10\n",
    "cnn_small_bn = Sequential()\n",
    "cnn_small_bn.add(Conv2D(16, kernel_size=(5, 5), padding=\"same\",\n",
    "                 input_shape=input_shape, kernel_regularizer=regularizer))\n",
    "cnn_small_bn.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "cnn_small_bn.add(BatchNormalization())\n",
    "cnn_small_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_small_bn.add(Conv2D(32, (5, 5), padding=\"same\", kernel_regularizer=regularizer))\n",
    "cnn_small_bn.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "#cnn_small_bn.add(BatchNormalization())\n",
    "\n",
    "cnn_small_bn.add(BatchNormalization())\n",
    "cnn_small_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_small_bn.add(Conv2D(32, (5, 5), padding=\"same\", kernel_regularizer=regularizer))\n",
    "cnn_small_bn.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "cnn_small_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_small_bn.add(Flatten())\n",
    "cnn_small_bn.add(Dense(512, activation='relu'))\n",
    "cnn_small_bn.add(Dense(num_classes, activation='softmax'))\n",
    "cnn_small_bn.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history_cnn_bn = cnn_small_bn.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_split=.1)\n",
    "cnn_small_bn.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Accuracy with Batch Norm: 89.5% without Batch Norm: 85.33%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab = pd.read_csv(\"annotations/list.txt\", sep=\" \", skiprows=[0,1,2,3,4,5],names = [\"Name\", \"class\",\"breed\",\"sdf\"])\n",
    "#test_lab = pd.read_csv(\"annotations/test.txt\", sep=\" \", names = [\"Name\", \"class\",\"breed\",\"sdf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_lab['class']\n",
    "#y_test = test_lab['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7349"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7349,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ert3 = image.load_img(\"images/Abyssinian_101.jpg\", target_size=(224,224))\n",
    "\n",
    "zxcbdf = image.img_to_array(ert3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zxcbdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = zxcbdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab.Name = train_lab.Name.str.replace('\\s+', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = train_lab[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam0 = names.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_data = np.array([1,2,3])\n",
    "y_lab = []\n",
    "X_data = []\n",
    "\n",
    "files = glob.glob(\"images/*.jpg\")\n",
    "for myFile in files:\n",
    "    result = re.search('images/(.*).jpg', myFile)\n",
    "    file_name = result.group(1)\n",
    "    file_name = \"\".join(file_name.split())\n",
    "    #print(file_name)\n",
    "    \n",
    "    if(file_name not in nam0):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    #image = cv2.imread (myFile)\n",
    "    \n",
    "    ert3 = image.load_img(myFile, target_size=(224,224))\n",
    "\n",
    "    zxcbdf1 = image.img_to_array(ert3)\n",
    "    \n",
    "    #train_lab.loc[train_lab['Name'] == file_name, 'sdf'] = image\n",
    "    #np.append(X_data, zxcbdf1, axis = 0)\n",
    "    X_data.append(zxcbdf1)\n",
    "    #train_lab.loc[train_lab['Name'] == file_name, \"breed\"] = \n",
    "    a = train_lab.loc[train_lab['Name'] == file_name, \"class\"].iloc[0]\n",
    "    y_lab.append(a)\n",
    "    #X_data.append(zxcbdf1)\n",
    "    #print(a)\n",
    "\n",
    "    #print(image.shape)\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fin = np.array(y_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7349"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([img for img in X_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7349, 224, 224, 3)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_fin = np.array(y_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"y.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"X.npy\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7349, 224, 224, 3)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "#model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "#img_path = 'elephant.jpg'\n",
    "#img = image.load_img(img_path, target_size=(224, 224))\n",
    "#x = image.img_to_array(img)\n",
    "#x = np.expand_dims(x, axis=0)\n",
    "#x = preprocess_input(x)\n",
    "#from keras.preprocessing import image\n",
    "#X = np.array([image.img_to_array(img) for img in images_carpet + images_ball])\n",
    "# load VGG16\n",
    "model = VGG16(include_top=False, weights='imagenet')\n",
    "# preprocessing for VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "X_pre = preprocess_input(X)\n",
    "features = model.predict(X_pre)\n",
    "\n",
    "#features = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7349, 224, 224, 3)\n",
      "(7349, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(features.shape)\n",
    "features_ = features.reshape(7349, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_fin = features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7349, 25088)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"features.npy\", feat_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat_fin, y, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC()\n",
    "\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8656147986942329"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0, 39,  2, ...,  1,  0,  0],\n",
       "       [ 0,  2, 31, ...,  6,  1,  0],\n",
       "       ...,\n",
       "       [ 0,  2,  5, ..., 33,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0, 48,  0],\n",
       "       [ 0,  0,  0, ...,  0,  1, 49]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, svc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning using VGG16 test accuracy: 86.56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cud9",
   "language": "python",
   "name": "cud9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
